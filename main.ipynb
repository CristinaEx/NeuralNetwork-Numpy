{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### mnist load #########################3\n",
    "\n",
    "import numpy\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 训练集文件\n",
    "train_images_idx3_ubyte_file = 'MNIST_data/train-images.idx3-ubyte'\n",
    "# 训练集标签文件\n",
    "train_labels_idx1_ubyte_file = 'MNIST_data/train-labels.idx1-ubyte'\n",
    "# 测试集文件\n",
    "test_images_idx3_ubyte_file = 'MNIST_data/t10k-images.idx3-ubyte'\n",
    "# 测试集标签文件\n",
    "test_labels_idx1_ubyte_file = 'MNIST_data/t10k-labels.idx1-ubyte'\n",
    "\n",
    "\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx3文件的通用函数\n",
    "    :param idx3_ubyte_file: idx3文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii' #因为数据结构中前4行的数据类型都是32位整型，所以采用i格式，但我们需要读取前4行数据，所以需要4个i。我们后面会看到标签集中，只使用2个ii。\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))\n",
    "\n",
    "    # 解析数据集\n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)  #获得数据在缓存中的指针位置，从前面介绍的数据结构可以看出，读取了前4行之后，指针位置（即偏移位置offset）指向0016。\n",
    "    print(offset)\n",
    "    fmt_image = '>' + str(image_size) + 'B'  #图像数据像素值的类型为unsigned char型，对应的format格式为B。这里还有加上图像大小784，是为了读取784个B格式数据，如果没有则只会读取一个值（即一副图像中的一个像素值）\n",
    "    print(fmt_image,offset,struct.calcsize(fmt_image))\n",
    "    images = numpy.empty((num_images, num_rows, num_cols))\n",
    "    #plt.figure()\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print('已解析 %d' % (i + 1) + '张')\n",
    "            print(offset)\n",
    "        images[i] = numpy.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        #print(images[i])\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "#        plt.imshow(images[i],'gray')\n",
    "#        plt.pause(0.00001)\n",
    "#        plt.show()\n",
    "    #plt.show()\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx1文件的通用函数\n",
    "    :param idx1_ubyte_file: idx1文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数和标签数\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))\n",
    "\n",
    "    # 解析数据集\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = numpy.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print ('已解析 %d' % (i + 1) + '张')\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  60000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*row*col维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*1维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  10000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*row*col维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  10000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*1维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### conv ##########################\n",
    "\n",
    "from math import floor,ceil\n",
    "\n",
    "def conv2d(data,filter,strides=[1,1],padding='SAME'):\n",
    "    \"\"\"\n",
    "    data:数据[batch_size,h,w,channel]\n",
    "    filter:卷积算子[h,w,channel_in,channel_out]\n",
    "    strides:步长[dh,dw]\n",
    "    padding:'VAILD' or 'SAME'\n",
    "    \"\"\"\n",
    "    batch_size,h,w,channel = data.shape\n",
    "    fh,fw,channel_in,channel_out = filter.shape\n",
    "    if padding == 'VAILD':\n",
    "        result = numpy.zeros((batch_size,floor((h-fh)/strides[0])+1,floor((w-fw)/strides[1])+1,channel_out))\n",
    "        for b in range(batch_size):\n",
    "            for m in range(floor((h-fh)/strides[0])+1):\n",
    "                x = int(m*strides[0])\n",
    "                for n in range(floor((w-fw)/strides[1])+1):\n",
    "                    y = int(n*strides[1])\n",
    "                    for c in range(channel_out):\n",
    "                        result[b,m,n,c]=sum(sum(sum(data[b,x:x+fh,y:y+fw,:]*filter[:,:,:,c])));\n",
    "    else:\n",
    "        data0 = numpy.pad(data,((0,0),(floor(fh/2),floor(fh/2)),(floor(fw/2),floor(fw/2)),(0,0)),'constant')\n",
    "        result0 = conv2d(data0,filter,strides,padding='VAILD')\n",
    "        result = result0[:,0:h,0:w,:]\n",
    "    return result\n",
    "\n",
    "def deconv2d(loss,filter,strides=[1,1],padding='SAME'):\n",
    "    \"\"\"\n",
    "    反卷积\n",
    "    计算loss传播\n",
    "    目前仅支持步长为1\n",
    "    \"\"\"\n",
    "    batch_size,h,w,channel = loss.shape\n",
    "    fh,fw,channel_in,channel_out = filter.shape\n",
    "    new_filter = filter.transpose(0,1,3,2) # output_channel转换\n",
    "    new_filter = numpy.flip(new_filter,0)\n",
    "    new_filter = numpy.flip(new_filter,1) # 算子上下左右翻转\n",
    "    if padding == 'VAILD':\n",
    "        data0 = numpy.pad(loss,((0,0),(fh-1,fh-1),(fw-1,fw-1),(0,0)),'constant')\n",
    "    else:\n",
    "        data0 = numpy.pad(loss,((0,0),(floor(fh/2),floor(fh/2)),(floor(fw/2),floor(fw/2)),(0,0)),'constant')\n",
    "    return conv2d(data0,new_filter,strides,'VAILD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## net #################################\n",
    "\n",
    "from os import mkdir\n",
    "from os.path import isdir,dirname,isfile\n",
    "\n",
    "class MainNet:\n",
    "    def __init__(self,net):\n",
    "        \"\"\"\n",
    "        net:第一个网络\n",
    "        \"\"\"\n",
    "        nets = [net] # 网络\n",
    "        pass\n",
    "\n",
    "    def addNet(self,net,lastNetPos=[0,0]):\n",
    "        \"\"\"\n",
    "        该网络在上一级网络的位置,比如net的输入[w,h,mod]在目前nets最后进入的网络的[w_pos,h_pos],默认为[0,0]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.data = None # 输入[batch_size,w,h,mod]\n",
    "        self.conv_layout = [] # 卷积层\n",
    "        self.conv_filter = [] # 每层卷积层对应卷积核\n",
    "        self.conv_bias = [] # 每个卷积核对应偏置项\n",
    "        self.st_func = [] # 每层网络对应激活函数\n",
    "        self.padding = [] # 每层网络对应padding方式\n",
    "        self.strides = [] # 每层网络卷积核对应步长\n",
    "        \n",
    "\n",
    "    def addData(self,data):\n",
    "        \"\"\"\n",
    "        添加数据，数据的shape只能改变batch_size\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def addConvLayout(self,filter_shape,bias=None,strides=[1,1,1,1],init_type='ZERO',padding='SAME',st_func='NONE'):\n",
    "        \"\"\"\n",
    "        使用前self.data必须构建初始值，或者0值填充\n",
    "        filter_shape:[w,h,input,output]\n",
    "        bias:None->默认偏置项,True:有偏置,False:无偏置\n",
    "        strides:步长\n",
    "        init_type='ZERO' or 'RANDOM' -> 初始置零或高斯分布(推荐RANDOM)\n",
    "        padding:VAILD or SAME\n",
    "        st_func:激活函数 NONE(√) SIGMOID(√) RELU LEAKY_RELU_(alpha值) TANH\n",
    "        \"\"\" \n",
    "        if bias == None:\n",
    "            self.conv_bias.append(numpy.array([]))\n",
    "        if init_type == 'ZERO':\n",
    "            self.conv_filter.append(numpy.zeros(filter_shape))\n",
    "            if not bias == None:\n",
    "                self.conv_bias.append(numpy.zeros(filter_shape[3]))\n",
    "        else:\n",
    "            self.conv_filter.append(numpy.random.standard_normal(filter_shape)/(filter_shape[0]*filter_shape[1]))\n",
    "            if not bias == None:\n",
    "                self.conv_bias.append(numpy.random.standard_normal(filter_shape[3]))\n",
    "        # if self.conv_layout:\n",
    "        #     data = self.conv_layout[-1]\n",
    "        # else:\n",
    "        #     data = self.data\n",
    "        # layout = conv2d(data,self.conv_filter[-1],strides,padding)\n",
    "        # if not bias == None:\n",
    "        #     for channel in range(filter_shape[3]):\n",
    "        #         layout[:,:,:,channel] += self.conv_bias[-1][channel]\n",
    "        # if st_func == 'SIGMOID':\n",
    "        #     layout = self.__sigmoid(layout)\n",
    "        self.st_func.append(st_func)\n",
    "        self.padding.append(padding)\n",
    "        self.strides.append(strides)\n",
    "        self.conv_layout.append(None)\n",
    "\n",
    "    def __sigmoid(self,x):\n",
    "        \"\"\"\n",
    "        sigmoid\n",
    "        return y = 1/(1+exp(-x))\n",
    "        \"\"\"\n",
    "        return 1/(1+numpy.exp(-x))\n",
    "\n",
    "    def __leakyRelu(self,x,alpha):\n",
    "        \"\"\"\n",
    "        leaky relu = (x<0)*alpha+(x>0)*1\n",
    "        \"\"\"\n",
    "        return ((x<0)*alpha+(x>0))*x\n",
    "\n",
    "    def __sigmoid_loss(self,y):\n",
    "        \"\"\"\n",
    "        y = 1/(1+exp(-x))\n",
    "        sigmoid 导数\n",
    "        返回dy/dx\n",
    "        \"\"\"\n",
    "        return y*(1-y)\n",
    "\n",
    "    def __leakyRelu_loss(self,y,alpha):\n",
    "        return (y<0)*alpha+(y>=0)\n",
    "\n",
    "    def load(self,fileName):\n",
    "        \"\"\"\n",
    "        读取\n",
    "        \"\"\"\n",
    "        if not isfile(fileName):\n",
    "            return False\n",
    "        self.__init__() # 初始化\n",
    "        with open(fileName) as f:\n",
    "            layout_num = int(f.readline())\n",
    "            for i in range(layout_num):\n",
    "                filter_size = [int(x) for x in list(f.readline()[1:-2].split(','))]\n",
    "                b = False\n",
    "                if len(list(f.readline())) >= 2:\n",
    "                    b = True\n",
    "                strides = [int(x) for x in list(f.readline()[1:-2].split(','))]\n",
    "                padding = f.readline()[0:-1]\n",
    "                st_func = f.readline()[0:-1]\n",
    "                self.addConvLayout(filter_size,bias = b,strides = strides,padding = padding,st_func = st_func)\n",
    "        for i in range(len(self.conv_filter)):\n",
    "            data = numpy.load(dirname(fileName) + '\\\\layout_'+str(i)+'.npz')\n",
    "            self.conv_filter[i]=data['x']\n",
    "            self.conv_bias[i]=data['y']\n",
    "        return True\n",
    "\n",
    "    def save(self,filename):\n",
    "        \"\"\"\n",
    "        保存\n",
    "        \"\"\"\n",
    "        if not isdir(dirname(filename)):\n",
    "            mkdir(dirname(filename))\n",
    "        with open(filename,'w+') as f:\n",
    "            f.write(str(len(self.conv_filter)))\n",
    "            f.write('\\n')\n",
    "            for i in range(len(self.conv_filter)):\n",
    "                f.write(str(self.conv_filter[i].shape))\n",
    "                f.write('\\n')\n",
    "                f.write(str(self.conv_bias[i].shape))\n",
    "                f.write('\\n')\n",
    "                f.write(str(self.strides[i]))\n",
    "                f.write('\\n')\n",
    "                f.write(str(self.padding[i]))\n",
    "                f.write('\\n')\n",
    "                f.write(str(self.st_func[i]))\n",
    "                f.write('\\n')\n",
    "        for i in range(len(self.conv_filter)):\n",
    "            numpy.savez(dirname(filename) + '\\\\layout_'+str(i),x=self.conv_filter[i],y=self.conv_bias[i])\n",
    "        return True\n",
    "\n",
    "    def regress(self,learning_rate,label,regress_type='SGD',loss_type='MSE'):\n",
    "        \"\"\"\n",
    "        后向传播，仅支持随机梯度下降\n",
    "        learing_rate:学习率\n",
    "        label:最后一层的标准输出\n",
    "        权值更新速率正比于learning_rate\n",
    "        loss_type:MSE or CE(交叉熵)\n",
    "        \"\"\"\n",
    "        self.count() # 更新权值\n",
    "        if regress_type == 'SGD':\n",
    "            now_layout = self.conv_layout[-1] # 当前layout\n",
    "            # -------------------------经过损失函数传播loss---------------------------------\n",
    "            if loss_type == 'CE':\n",
    "                min_error = 0.000000001\n",
    "                loss = (-label/(now_layout+min_error)+(1-label)/(1-now_layout+min_error))\n",
    "            else:\n",
    "                loss = 2*(now_layout-label) # loss = d_loss/\n",
    "            # -------------------------------------------------------------------------------\n",
    "            for i in range(1,len(self.conv_layout)+1):\n",
    "                now_layout = self.conv_layout[-i] # 当前layout\n",
    "                if i == len(self.conv_layout):\n",
    "                    last_layout = self.data\n",
    "                else:\n",
    "                    last_layout = self.conv_layout[-i-1]\n",
    "                batch_size,h,w,channel = last_layout.shape\n",
    "                fh,fw,channel_in,channel_out = self.conv_filter[-i].shape # 当前filter\n",
    "                # true_layout = st_func^(-1)(label)\n",
    "                # ---------------------经过激活函数传播loss------------------------\n",
    "                if self.st_func[-i] == 'SIGMOID':\n",
    "                    loss = loss*self.__sigmoid_loss(now_layout)# loss = (d_loss/d_st_func_out_put) * (d_st_func_out_put/d_hidden_output) = d_loss/d_hidden_output\n",
    "                elif self.st_func[-i][0:10] == 'LEAKY_RELU':\n",
    "                    alpha = float(self.st_func[-i][11:])\n",
    "                    loss = loss*self.__leakyRelu_loss(now_layout,alpha)\n",
    "                # -----------------------------------------------------------------\n",
    "                # 注:d_hidden_output/dw = data\n",
    "                # 进行随机梯度下降更新权值\n",
    "                data = last_layout\n",
    "                if self.padding[-i] == 'SAME':\n",
    "                    data = numpy.pad(data,((0,0),(floor(fh/2),floor(fh/2)),(floor(fw/2),floor(fw/2)),(0,0)),'constant')\n",
    "                # conv(data,filter[-1],strides,'VAILD') = now_layout\n",
    "                # filter[-1] = filter[-1]-sum(```在batch_size维度上累加```learning_rate*loss*data[batch_size,x0:x0+fw,y0:y0+fh,:]/filter_size)\n",
    "                SGD_K = 0.1 # 随机抽取其中的0.1倍进行回归\n",
    "                [batch_size,m,n,channel_out] = loss.shape\n",
    "                SGD_NUM = ceil(m*n*SGD_K) # 每个batch抽取SGD_NUM个区域进行回归,每个区域大小为[fh,fw,channel_in]\n",
    "                # [fh,fw,channel_in] .* [fh,fw,channel_in,channel_out] = [1,1,channel_out] \n",
    "                # [fh,fw,channel_in,cho] = [fh,fw,channel_in] * [1,1,cho] .* learning_rate / filter_size\n",
    "                filter_loss = numpy.zeros(self.conv_filter[-i].shape)\n",
    "                bias = not len(self.conv_bias[-i]) == 0\n",
    "                if bias:\n",
    "                    bias_loss = numpy.zeros(self.conv_bias[-i].shape)\n",
    "                [lb,lh,lw,lc] = loss.shape\n",
    "                # --------------------------随机梯度下降------------------------------\n",
    "                x0 = numpy.random.randint(lh,size=SGD_NUM)\n",
    "                y0 = numpy.random.randint(lw,size=SGD_NUM)\n",
    "                K = learning_rate/SGD_NUM/batch_size\n",
    "                for b in range(batch_size):\n",
    "                    for j in range(SGD_NUM):\n",
    "                        x = x0[j]*self.strides[-i][0]\n",
    "                        y = y0[j]*self.strides[-i][0]\n",
    "                        for ch in range(channel_out):\n",
    "                            filter_loss[:,:,:,ch] = filter_loss[:,:,:,ch] + loss[b,x,y,ch] * data[b,x:x+fh,y:y+fw,:]*K\n",
    "                            if bias:\n",
    "                                bias_loss[ch] = loss[b,x,y,ch]*K\n",
    "                # ------------------------------------------------------------------\n",
    "                loss = deconv2d(loss,self.conv_filter[-i],self.strides[-i],self.padding[-i]) # 更新loss\n",
    "\n",
    "                # 更新后的卷积算子权值\n",
    "                self.conv_filter[-i] = self.conv_filter[-i] - filter_loss\n",
    "                if bias:\n",
    "                    self.conv_bias[-i] = self.conv_bias[-i] - bias_loss\n",
    "\n",
    "    def count(self):\n",
    "        \"\"\"\n",
    "        前向传播，得出结果，输出最后一层\n",
    "        \"\"\"\n",
    "        last_layout = self.data\n",
    "        for i in range(len(self.conv_layout)):\n",
    "            layout = conv2d(last_layout,self.conv_filter[i],self.strides[i],self.padding[i])\n",
    "            if not len(self.conv_bias[i]) == 0:\n",
    "                filter_shape = self.conv_filter[i].shape\n",
    "                for channel in range(filter_shape[3]):\n",
    "                    layout[:,:,:,channel] += self.conv_bias[i][channel]\n",
    "            if self.st_func[i] == 'SIGMOID':\n",
    "                layout = self.__sigmoid(layout);\n",
    "            elif self.st_func[i][0:10] == 'LEAKY_RELU':\n",
    "                alpha = float(self.st_func[i][11:])\n",
    "                layout = self.__leakyRelu(layout,alpha)\n",
    "            self.conv_layout[i] = layout\n",
    "            last_layout = layout\n",
    "        return last_layout\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        返回网络参数\n",
    "        \"\"\"\n",
    "        result = 'input_data:'\n",
    "        result += str(self.data.shape) + '\\n'\n",
    "        for i in range(len(self.conv_layout)):\n",
    "            result += 'filter:'\n",
    "            result += str(self.conv_filter[i].shape) + '      '\n",
    "            result += 'bias:'\n",
    "            if not len(self.conv_bias[i]) == 0:\n",
    "                result += str(self.conv_bias[i].shape) + '      \\n'\n",
    "            else:\n",
    "                result += 'None' + '      \\n'\n",
    "            result += 'st_func:' + self.st_func[i] + '\\n'\n",
    "            result += ('layout_' + str(i) + ':')\n",
    "            result += str(self.conv_layout[i].shape) + '      \\n'         \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### train ###############################\n",
    "\n",
    "import random\n",
    "\n",
    "MODEL_PATH_OLD = 'model_old\\\\3_3+3_3+5_5+connect\\\\model_200\\\\model.dat'\n",
    "MODEL_PATH = 'model\\\\model.dat'\n",
    "\n",
    "def num2oneHot(nums,len_):\n",
    "    \"\"\"\n",
    "    nums:列表\n",
    "    len_:one-hot向量长度\n",
    "    return one-hot 向量[0:len-1]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(len(nums)):\n",
    "        result.append([])\n",
    "        num = int(nums[i])\n",
    "        for j in range(num):\n",
    "            result[i].append(0)\n",
    "        result[i].append(1)\n",
    "        for j in range(len_-num-1):\n",
    "            result[i].append(0)\n",
    "    return result\n",
    "\n",
    "def train():\n",
    "    train_images = load_train_images()\n",
    "    train_labels = load_train_labels()\n",
    "    \n",
    "    batch_size = 30\n",
    "    learning_rate = 0.0001\n",
    "    train_num = 1000 # 训练次数\n",
    "    it_num = 10 # 每次迭代次数\n",
    "    init_type = 'RANDOM'\n",
    "\n",
    "    net = Net()\n",
    "    if not net.load(MODEL_PATH):      \n",
    "        net.addConvLayout([3,3,1,4],bias = True,padding='VAILD',init_type=init_type,st_func='LEAKY_RELU_0.01')\n",
    "        net.addConvLayout([3,3,4,8],bias = True,padding='VAILD',init_type=init_type,st_func='LEAKY_RELU_0.01')\n",
    "        net.addConvLayout([5,5,8,16],bias = True,padding='VAILD',init_type=init_type,st_func='LEAKY_RELU_0.01')\n",
    "        net.addConvLayout([5,5,16,32],bias = True,padding='VAILD',init_type=init_type,st_func='LEAKY_RELU_0.01')\n",
    "        net.addConvLayout([16,16,32,64],bias = True,padding='VAILD',st_func='SIGMOID',init_type=init_type)\n",
    "        net.addConvLayout([1,1,64,10],bias = True,padding='VAILD',st_func='SIGMOID',init_type=init_type)\n",
    "\n",
    "    for j in range(train_num):\n",
    "        index = random.randint(1,len(train_images)-batch_size-1)\n",
    "        # index = 0\n",
    "        data = train_images[index:index+batch_size]\n",
    "        data = numpy.reshape(data,[batch_size,28,28,1])\n",
    "        label = train_labels[index:index+batch_size]\n",
    "        # 改为one_hot向量\n",
    "        label = num2oneHot(label,10)\n",
    "        label = numpy.reshape(label,[batch_size,1,1,10])\n",
    "        net.addData(data)\n",
    "        for i in range(it_num):\n",
    "            loss = sum(sum(sum(sum(abs(net.count()-label)))))/batch_size\n",
    "            # print(net.conv_filter[0][:,:,0,0])\n",
    "            print(loss)\n",
    "            net.regress(learning_rate,label,regress_type='SGD',loss_type = 'CE')  # 交叉熵\n",
    "        print('saving...')\n",
    "        net.save(MODEL_PATH)\n",
    "        print('finish!') \n",
    "        learning_rate = 0.995*learning_rate\n",
    "        \n",
    "    loss = sum(sum(sum(sum(abs(net.count()-label)))))/batch_size\n",
    "    print(loss)\n",
    "\n",
    "    net.save(MODEL_PATH)\n",
    "\n",
    "def test():\n",
    "    test_images = load_test_images()\n",
    "    test_labels = load_test_labels()\n",
    "\n",
    "    test_num = 10\n",
    "\n",
    "    net = Net()\n",
    "    net.load(MODEL_PATH)\n",
    "\n",
    "    for i in range(test_num):\n",
    "        index = random.randint(1,len(test_images)-2)\n",
    "        # index = i\n",
    "        data = test_images[index]\n",
    "        data = numpy.reshape(data,[1,28,28,1])\n",
    "        label = test_labels[index]\n",
    "        print('correct result:'+str(int(label)))\n",
    "        net.addData(data)\n",
    "        result = net.count()[0,0,0,:]\n",
    "        j = 0\n",
    "        for i in range(len(result)):\n",
    "            if result[i] > result[j]:\n",
    "                j = i\n",
    "        print('net result:'+str(j))\n",
    "\n",
    "# 训练或简要测试请去除下列函数的注释标号\n",
    "# train()\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "魔数:2051, 图片数量: 10000张, 图片大小: 28*28\n16\n>784B 16 784\n已解析 10000张\n7839232\n魔数:2049, 图片数量: 10000张\n已解析 10000张\n"
    }
   ],
   "source": [
    "############################ visual test ##############################\n",
    "import tkinter as tk\n",
    "from PIL import Image,ImageTk\n",
    "\n",
    "class MnistVisualTest(tk.Frame):\n",
    "    def __init__(self, master=None):\n",
    "        super().__init__(master)\n",
    "        self.master = master\n",
    "        self.pack()\n",
    "        self.create_widgets()\n",
    "        self.test_images = load_test_images()\n",
    "        self.test_labels = load_test_labels()\n",
    "        self.net = Net()\n",
    "        self.net.load(MODEL_PATH)\n",
    "\n",
    "        self.writeboard_items = []\n",
    "        \n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.fm1=tk.Frame(self)\n",
    "        self.fm1.grid(column = 0)\n",
    "\n",
    "        self.txt1 = tk.StringVar()\n",
    "        self.txt1.set('点击RandomTest进行随机测试')\n",
    "        self.label1 = tk.Label(self.fm1,textvariable=self.txt1).grid(row=0)\n",
    "        self.txt2 = tk.StringVar()\n",
    "        self.txt2.set('当前未进行测试')\n",
    "        self.label2 = tk.Label(self.fm1,textvariable=self.txt2).grid(row=2)\n",
    "        self.b_random_test = tk.Button(self.fm1)\n",
    "        self.b_random_test[\"text\"] = \"RandomTest\"\n",
    "        self.b_random_test[\"command\"] = self.randomTest\n",
    "        self.b_random_test.grid(row = 3)\n",
    "        self.b_test_all = tk.Button(self.fm1)\n",
    "        self.b_test_all[\"text\"] = \"TestAll(检测速率很慢)\"\n",
    "        self.b_test_all[\"command\"] = self.testAll\n",
    "        self.b_test_all.grid(row = 4)\n",
    "\n",
    "        self.fm2=tk.Frame(self)\n",
    "        self.fm2.grid(column = 1,row = 0)\n",
    "        self.label2 = tk.Label(self.fm2,text='手写测试').grid(row=0)\n",
    "        self.writeboard = tk.Canvas(self.fm2, width=200, height=200)\n",
    "        self.writeboard.grid(row = 1)\n",
    "        self.writeboard.bind(\"<B1-Motion>\",self.paint)\n",
    "        self.writeboard_array = numpy.zeros([200,200])\n",
    "\n",
    "        self.fm3=tk.Frame(self.fm2)\n",
    "        self.fm3.grid(row=3)\n",
    "        self.b_clear = tk.Button(self.fm3)\n",
    "        self.b_clear[\"text\"] = \"clear\"\n",
    "        self.b_clear[\"command\"] = self.clear\n",
    "        self.b_clear.grid(column=0,row = 0)\n",
    "        self.b_count = tk.Button(self.fm3)\n",
    "        self.b_count[\"text\"] = \"count\"\n",
    "        self.b_count[\"command\"] = self.count\n",
    "        self.b_count.grid(column=1,row = 0)\n",
    "\n",
    "        self.txt3 = tk.StringVar()\n",
    "        self.txt3.set('当前未进行测试')\n",
    "        self.label3 = tk.Label(self.fm2,textvariable=self.txt3).grid(row=2)\n",
    "\n",
    "    def count(self):\n",
    "        data = self.writeboard_array\n",
    "        # 归一化为mnist形式\n",
    "        top_y=0\n",
    "        down_y=len(data)\n",
    "        number = False\n",
    "        for i in range(len(data)):\n",
    "            useful = False\n",
    "            if number:\n",
    "                useful = True\n",
    "            for j in range(len(data[i])):\n",
    "                if data[i][j] > 100:\n",
    "                    if number:\n",
    "                        useful = False\n",
    "                        break\n",
    "                    else:\n",
    "                        number = not number\n",
    "                        top_y = i\n",
    "                    break\n",
    "            if useful:\n",
    "                down_y = i\n",
    "                break\n",
    "        top_x=0\n",
    "        down_x=len(data[0])\n",
    "        number = False\n",
    "        for i in range(len(data[0])):\n",
    "            useful = False\n",
    "            if number:\n",
    "                useful = True\n",
    "            for j in range(len(data)):\n",
    "                if data[j][i] > 100:\n",
    "                    if number:\n",
    "                        useful = False\n",
    "                        break\n",
    "                    else:\n",
    "                        number = not number\n",
    "                        top_x = i\n",
    "                    break\n",
    "            if useful:\n",
    "                down_x = i\n",
    "                break\n",
    "        data = data[top_y:down_y,top_x:down_x]\n",
    "        pad_p=0.15\n",
    "        if down_y-top_y>down_x-top_x:\n",
    "            pad_y = int((down_y-top_y)*pad_p)\n",
    "            pad_x = int((down_y-top_y-(down_x-top_x))/2+pad_y)\n",
    "        else:\n",
    "            pad_x = int((down_x-top_x)*pad_p)\n",
    "            pad_y = int((down_x-top_x-(down_y-top_y))/2+pad_x)\n",
    "        data = numpy.pad(data,((pad_y,pad_y),(pad_x,pad_x)),'constant')\n",
    "        im = Image.fromarray(data)\n",
    "        im = im.convert('L')\n",
    "        im = im.resize((28,28))\n",
    "        data = numpy.array(im)\n",
    "        data = numpy.reshape(data,[1,28,28,1])\n",
    "        self.net.addData(data)\n",
    "        result = self.net.count()[0,0,0,:]\n",
    "        j = 0\n",
    "        for i in range(len(result)):\n",
    "            if result[i] > result[j]:\n",
    "                j = i\n",
    "        self.txt3.set(\"net result:\"+str(j))\n",
    "\n",
    "    def clear(self):\n",
    "        self.writeboard_array = numpy.zeros([200,200])\n",
    "        for item in self.writeboard_items:\n",
    "            self.writeboard.delete(item)\n",
    "        self.writeboard_items = []\n",
    "        self.txt3.set('当前未进行测试')\n",
    "\n",
    "    def paint(self,event):\n",
    "        pad = 13\n",
    "        pad_div=int(pad/2)\n",
    "        x1,y1 = (event.x - pad_div), (event.y - pad_div)\n",
    "        x2,y2 = (event.x + pad_div), (event.y + pad_div)\n",
    "        item = self.writeboard.create_oval(x1, y1, x2, y2, fill=\"red\")\n",
    "        self.writeboard_items.append(item)\n",
    "        for i in range(pad):\n",
    "            for j in range(pad):\n",
    "                try:\n",
    "                    self.writeboard_array[event.y-i+pad_div][event.x-j+pad_div] = 255\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def randomTest(self):\n",
    "        index = random.randint(1,len(self.test_images)-2)\n",
    "        data = self.test_images[index]\n",
    "        im = Image.fromarray(data)\n",
    "        im = im.convert('L')\n",
    "        # im = im.resize((400,400))\n",
    "        render= ImageTk.PhotoImage(im)  \n",
    "        img = tk.Label(self.fm1,image=render)\n",
    "        img.image = render\n",
    "        img.grid(row=1)\n",
    "        # net\n",
    "        data = numpy.reshape(data,[1,28,28,1])\n",
    "        label = self.test_labels[index]\n",
    "        self.txt1.set('label:'+str(int(label)))\n",
    "        self.net.addData(data)\n",
    "        result = self.net.count()[0,0,0,:]\n",
    "        j = 0\n",
    "        for i in range(len(result)):\n",
    "            if result[i] > result[j]:\n",
    "                j = i\n",
    "        self.txt2.set(\"net result:\"+str(j))\n",
    "\n",
    "    def testAll(self):\n",
    "        correct_num = 0\n",
    "        error_num = 0\n",
    "        for i in range(len(self.test_images)):\n",
    "            if i % 1000 == 0:\n",
    "                self.txt1.set(\"test\"+str(i*1000)+'~'+str((i+1)*1000)+'...')\n",
    "            data = self.test_images[i]\n",
    "            data = numpy.reshape(data,[1,28,28,1])\n",
    "            label = self.test_labels[i]\n",
    "            self.net.addData(data)\n",
    "            result = self.net.count()[0,0,0,:]\n",
    "            j = 0\n",
    "            for i in range(len(result)):\n",
    "                if result[i] > result[j]:\n",
    "                    j = i\n",
    "            if int(label) == j:\n",
    "                correct_num += 1\n",
    "            else:\n",
    "                error_num += 1\n",
    "        self.txt1.set(\"finish!\")\n",
    "        self.txt2.set(\"correct_rate:\"+str(correct_num/(correct_num+error_num)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    # root.geometry(\"500x500\")\n",
    "    mainview = MnistVisualTest(master=root)\n",
    "    mainview.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36564bitvirtualenv2f687d35fa874d7992dbcac325c7a13c",
   "display_name": "Python 3.6.5 64-bit (virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}